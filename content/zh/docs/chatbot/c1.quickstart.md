---
title: 快速开始
slug: 快速开始
description: 介绍主要功能
url: "docs/快速开始"
aliases:
- "/docs/快速开始"
---

## 🚀 快速使用

请自行安装 nvidia 驱动程序，本项目已在 Python 3.9.18，CUDA 11.7 环境下，Windows、X86 架构的 macOS 系统中完成测试。

Docker安装、私有化LLM接入及相关启动问题见：[快速使用明细](/docs/start-detail-zh)

### python 环境准备

- 推荐采用 conda 对 python 环境进行管理（可选）
```bash
# 准备 conda 环境
conda create --name devopsgpt python=3.9
conda activate devopsgpt
```

- 安装相关依赖
```bash
cd codefuse-chatbot
# python=3.9，notebook用最新即可，python=3.8用notebook=6.5.6
pip install -r requirements.txt
```

### 基础配置

```bash
# 修改服务启动的基础配置
cd configs
cp model_config.py.example model_config.py
cp server_config.py.example server_config.py

# model_config#11~12 若需要使用openai接口，openai接口key
os.environ["OPENAI_API_KEY"] = "sk-xxx"
# 可自行替换自己需要的api_base_url
os.environ["API_BASE_URL"] = "https://api.openai.com/v1"

# vi model_config#LLM_MODEL 你需要选择的语言模型
LLM_MODEL = "gpt-3.5-turbo"
LLM_MODELs = ["gpt-3.5-turbo"]

# vi model_config#EMBEDDING_MODEL 你需要选择的私有化向量模型
EMBEDDING_ENGINE = 'model'
EMBEDDING_MODEL = "text2vec-base"

# vi model_config#embedding_model_dict 修改成你的本地路径，如果能直接连接huggingface则无需修改
# 若模型地址为：
model_dir: ~/codefuse-chatbot/embedding_models/shibing624/text2vec-base-chinese
# 配置如下
"text2vec-base": "shibing624/text2vec-base-chinese",

# vi server_config#8~14, 推荐采用容器启动服务
DOCKER_SERVICE = True
# 是否采用容器沙箱
SANDBOX_DO_REMOTE = True
# 是否采用api服务来进行
NO_REMOTE_API = True
```

### 启动服务

默认只启动webui相关服务，未启动fastchat（可选）。
```bash
# 若需要支撑codellama-34b-int4模型，需要给fastchat打一个补丁
# cp examples/gptq.py ~/site-packages/fastchat/modules/gptq.py
# dev_opsgpt/service/llm_api.py#258 修改为 kwargs={"gptq_wbits": 4},

# start llm-service（可选）
python dev_opsgpt/service/llm_api.py
```
更多LLM接入方法见[详情...](/docs/fastchat-zh)
<br>

```bash
# 完成server_config.py配置后，可一键启动
cd examples
python start.py
```
