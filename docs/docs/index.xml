<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docs on CodeFuse</title>
    <link>/docs/</link>
    <description>Recent content in Docs on CodeFuse</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <atom:link href="/docs/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Acknowledgements</title>
      <link>/docs/acnowledgements/acknowledgements/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/acnowledgements/acknowledgements/</guid>
      <description>CodeFuse-ai 主页基于docura构建，在此深深感谢他们的开源贡献！&#xA;ChatBot 项目基于langchain-chatchat和codebox-api，在此深深感谢他们的开源贡献！</description>
    </item>
    <item>
      <title>ChatBot-RoadMap</title>
      <link>/docs/chatbot-roadmap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/chatbot-roadmap/</guid>
      <description>RoadMap 完整路线&#xA;Sandbox 环境 环境隔离的sandbox环境与代码执行 上传、下载文件 支持java执行环境 Vector Database &amp;amp; Retrieval task retrieval tool retrieval Prompt Management memory Management Multi Agent PRD需求文档、系分、接口设计 根据需求文档、系分、接口设计生产代码 自动测试、自动debugger 运维流程接入（ToolLearning） 全流程自动 基于fastchat接入LLM 基于sentencebert接入Text Embedding 向量加载速度提升 Connector 基于langchain的react模式 基于langchain完成tool检索 Web Crawl 通用能力 技术文档: 知乎、csdn、阿里云开发者论坛、腾讯云开发者论坛等 issue document SDK Library Document v0.0 Sandbox 环境 环境隔离的sandbox环境与代码执行 基于fastchat接入LLM 基于sentencebert接入Text Embedding Web Crawl 通用能力：技术文档: 知乎、csdn、阿里云开发者论坛、腾讯云开发者论坛等 v0.1 Sandbox 环境: 上传、下载文件 Vector Database &amp;amp; Retrieval task retrieval tool retrieval Connector 基于langchain的react模式 基于sentencebert接入Text Embedding: 向量加载速度提升 Done v0.</description>
    </item>
    <item>
      <title>Codefuse-ChatBot Development by Private Knowledge Augmentation</title>
      <link>/docs/codefuse-chatbot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/codefuse-chatbot/</guid>
      <description>中文&amp;nbsp ｜ &amp;nbspEnglish&amp;nbsp This project is an open-source AI intelligent assistant, specifically designed for the entire lifecycle of software development, covering design, coding, testing, deployment, and operations. Through knowledge retrieval, tool utilization, and sandbox execution, Codefuse-ChatBot can not only answer professional questions you encounter during the development process but also coordinate multiple independent, dispersed platforms through a conversational interface.&#xA;📜 Contents 🤝 Introduction 🧭 Technical Route 🤝 Introduction 💡 The aim of this project is to construct an AI intelligent assistant for the entire lifecycle of software development, covering design, coding, testing, deployment, and operations, through Retrieval Augmented Generation (RAG), Tool Learning, and sandbox environments.</description>
    </item>
    <item>
      <title>codefuse-devops-eval</title>
      <link>/docs/codefuse-devops-eval/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/codefuse-devops-eval/</guid>
      <description>Comming soon</description>
    </item>
    <item>
      <title>codefuse-devops-model</title>
      <link>/docs/codefuse-devops-model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/codefuse-devops-model/</guid>
      <description>Comming soon</description>
    </item>
    <item>
      <title>CodeFuse-ModelCache</title>
      <link>/docs/codefuse-modelcache/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/codefuse-modelcache/</guid>
      <description>CodeFuse-ModelCache CodeFuse-ModelCache</description>
    </item>
    <item>
      <title>CodeFuse-Query</title>
      <link>/docs/codefuse-query/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/codefuse-query/</guid>
      <description>CodeFuse-Query CodeFuse-Query</description>
    </item>
    <item>
      <title>Configurations</title>
      <link>/docs/configurations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/configurations/</guid>
      <description>本地私有化/大模型接口接入 依托于开源的 LLM 与 Embedding 模型，本项目可实现基于开源模型的离线私有部署。此外，本项目也支持 OpenAI API 的调用。&#xA;📜 目录 本地私有化模型接入 公开大模型接口接入 启动大模型服务 本地私有化模型接入 模型地址配置示例，model_config.py配置修改&#xA;# 建议：走huggingface接入，尽量使用chat模型，不要使用base，无法获取正确输出 # 注意：当llm_model_dict和VLLM_MODEL_DICT同时存在时，优先启动VLLM_MODEL_DICT中的模型配置 # llm_model_dict 配置接入示例如下 llm_model_dict = { &amp;#34;chatglm-6b&amp;#34;: { &amp;#34;local_model_path&amp;#34;: &amp;#34;THUDM/chatglm-6b&amp;#34;, &amp;#34;api_base_url&amp;#34;: &amp;#34;http://localhost:8888/v1&amp;#34;, # &amp;#34;name&amp;#34;修改为fastchat服务中的&amp;#34;api_base_url&amp;#34; &amp;#34;api_key&amp;#34;: &amp;#34;EMPTY&amp;#34; } } # VLLM_MODEL_DICT 配置接入示例如下 VLLM_MODEL_DICT = { &amp;#39;chatglm2-6b&amp;#39;: &amp;#34;THUDM/chatglm-6b&amp;#34;, } 模型路径填写示例&#xA;# 1、若把模型放到 ~/codefuse-chatbot/llm_models 路径下 # 若模型地址如下 model_dir: ~/codefuse-chatbot/llm_models/THUDM/chatglm-6b # 参考配置如下 llm_model_dict = { &amp;#34;chatglm-6b&amp;#34;: { &amp;#34;local_model_path&amp;#34;: &amp;#34;THUDM/chatglm-6b&amp;#34;, &amp;#34;api_base_url&amp;#34;: &amp;#34;http://localhost:8888/v1&amp;#34;, # &amp;#34;name&amp;#34;修改为fastchat服务中的&amp;#34;api_base_url&amp;#34; &amp;#34;api_key&amp;#34;: &amp;#34;EMPTY&amp;#34; } } VLLM_MODEL_DICT = { &amp;#39;chatglm2-6b&amp;#39;: &amp;#34;THUDM/chatglm-6b&amp;#34;, } # or 若模型地址如下 model_dir: ~/codefuse-chatbot/llm_models/chatglm-6b llm_model_dict = { &amp;#34;chatglm-6b&amp;#34;: { &amp;#34;local_model_path&amp;#34;: &amp;#34;chatglm-6b&amp;#34;, &amp;#34;api_base_url&amp;#34;: &amp;#34;http://localhost:8888/v1&amp;#34;, # &amp;#34;name&amp;#34;修改为fastchat服务中的&amp;#34;api_base_url&amp;#34; &amp;#34;api_key&amp;#34;: &amp;#34;EMPTY&amp;#34; } } VLLM_MODEL_DICT = { &amp;#39;chatglm2-6b&amp;#39;: &amp;#34;chatglm-6b&amp;#34;, } # 2、若不想移动相关模型到 ~/codefuse-chatbot/llm_models # 同时删除 `模型路径重置` 以下的相关代码，具体见model_config.</description>
    </item>
    <item>
      <title>FasterTransformer4CodeFuse</title>
      <link>/docs/fastertransformer4codefuse/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/fastertransformer4codefuse/</guid>
      <description>FasterTransformer4CodeFuse FasterTransformer4CodeFuse</description>
    </item>
    <item>
      <title>MFTCoder</title>
      <link>/docs/mftcoder/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/mftcoder/</guid>
      <description>MFTCoder MFTCoder</description>
    </item>
    <item>
      <title>Multi-Agent</title>
      <link>/multi-agent/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/multi-agent/</guid>
      <description>📜 目录 简介 模块介绍 快速使用 简介 为了提高大型模型在推理准确性方面的表现，业界出现了多种创新的大型语言模型(LLM)玩法。从最早的CoT、ToT到GoT，这些方法不断拓展了LLM的能力边界。在处理复杂问题时，我们可以通过ReAct过程来选择、调用和执行工具反馈，同时实现多轮工具使用和多步骤执行。&#xA;但对于更复杂的场景，例如复杂代码的开发，单一功能的LLM Agent显然难以胜任。因此，社区开始发展出多Agent的组合玩法，比如专注于metaGPT、GPT-Engineer、chatDev等开发领域的项目，以及专注于自动化构建Agent和Agent对话的AutoGen项目。&#xA;经过对这些框架的深入分析，发现大多数的Agent框架整体耦合度较高，其易用性和可扩展性较差。在预设场景中实现特定场景，但想要进行场景扩展却困难重重。&#xA;因此，我们希望构建一个可扩展、易于使用的Multi-Agent框架，以支持ChatBot在获取知识库信息的同时，能够辅助完成日常办公、数据分析、开发运维等各种通用任务。&#xA;本项目的Mutli-Agent框架汲取兼容了多个框架的优秀设计，比如metaGPT中的消息池（message pool）、autogen中的代理选择器（agent selector）等。&#xA;以下模块将从5个方面介绍Multi Agent框架所需要素：&#xA;Agent Communication在Multi Agent框架中，确保Agent可以有效地进行信息交流对于管理上下文以及提高问答效率至关重要。 a. 遵循简洁直观易于理解的链式对话原则，将Agent以线性方式排列串连成一个执行链路。 b. 借鉴metaGPT中的Message Pool框架，允许Agent对Message Pool进行推送和订阅，使链路更加灵活。有利于精细化Prompt工程的场景，但难以把握复杂链路的关系分析。 Standard Operation Process（SOP）：对LLM的生成结果进行标准化解析和处理。 a. 定义Agent的 Input 和 Output 范围，能够组装和解析相关Action和Status，保证框架运行的稳定性 b. 封装多种基础Action执行模块，如Tool Using、Planning、Coding、Direct Answering、final answer等SOP标识，以满足Agent的基本工作需求。 Plan and Executor：增加LLM的Tool使用、Agent调度、代码的生成。设置了几种基本链路，例如： a. 单轮问答，也可以扩展到CoT、ToT、GoT等形式。 b. ReAct，基础的响应决策过程，模型设置SOP 状态以终止循环 c. TaskPlaning - Executor，任务完成即可结束 Long-short term memory Management：Multi-Agent与单Agent的关键区别在于，Multi-Agent需要处理大量的交流信息，类似人类团队协作的过程。增加一个专门负责内容总结（类似于会议助理）的Agent，对长期记忆进行总结并提更有效信息传递给下一位Agent，而非传递所有内容给下一位Agent。 Human-agent interaction：面对复杂场景时，需要人类介入Agent交互过程并提供反馈。通过上述 Long-short term memory Management 和 Agent Communication 过程，使LLM能准确理解人类的意图，从而更有效地完成任务。 总的来说，这五个要素共同构建了一个Multi Agent框架，确保Agent之间的协作更加紧密和高效，同时也能够适应更复杂的任务需求和更多样的交互场景。通过组合多个Agent链路来实现一个完整且复杂的项目上线场景（Dev Phase），如Demand Chain（CEO）、Product Arguement Chain（CPO、CFO、CTO）、Engineer Group Chain（Selector、Developer1~N）、QA Engineer Chain（Developer、Tester）、Deploy Chain（Developer、Deploer）。</description>
    </item>
    <item>
      <title>overview</title>
      <link>/docs/en_overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/en_overview/</guid>
      <description>HuggingFace | ModelScope Hello World! This is CodeFuse! CodeFuse aims to develop Code Large Language Models (Code LLMs) to support and enhance full-lifecycle AI native sotware developing, covering crucial stages such as design requirements, coding, testing, building, deployment, operations, and insight analysis.&#xA;We are passionating about creating innovative open-source solutions that empower developers throughout the software development process as shown above. We also encourage engineers and researchers within this community to join us in co-constructing/improving CodeFuse.</description>
    </item>
    <item>
      <title>QuickStart</title>
      <link>/docs/quickstart/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/quickstart/</guid>
      <description>🚀 Quick Start Please install the Nvidia driver yourself; this project has been tested on Python 3.9.18, CUDA 11.7, Windows, and X86 architecture macOS systems.&#xA;Preparation of Python environment It is recommended to use conda to manage the python environment (optional) # Prepare conda environment conda create --name Codefusegpt python=3.9 conda activate Codefusegpt Install related dependencies cd Codefuse-ChatBot # python=3.9，use notebook-latest，python=3.8 use notebook==6.5.5 pip install -r requirements.txt Basic Configuration # Modify the basic configuration for service startup cd configs cp model_config.</description>
    </item>
    <item>
      <title>Start-Detail</title>
      <link>/docs/chatbot/start-detail/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/chatbot/start-detail/</guid>
      <description>请自行安装 nvidia 驱动程序，本项目已在 Python 3.9.18，CUDA 11.7 环境下，Windows、X86 架构的 macOS 系统中完成测试。&#xA;python 环境准备 推荐采用 conda 对 python 环境进行管理（可选） # 准备 conda 环境 conda create --name devopsgpt python=3.9 conda activate devopsgpt 安装相关依赖 cd codefuse-chatbot # python=3.9，notebook用最新即可，python=3.8用notebook=6.5.6 pip install -r requirements.txt 沙盒环境准备 windows Docker 安装： Docker Desktop for Windows 支持 64 位版本的 Windows 10 Pro，且必须开启 Hyper-V（若版本为 v1903 及以上则无需开启 Hyper-V），或者 64 位版本的 Windows 10 Home v1903 及以上版本。&#xA;【全面详细】Windows10 Docker安装详细教程 Docker 从入门到实践 Docker Desktop requires the Server service to be enabled 处理 安装wsl或者等报错提示 Linux Docker 安装： Linux 安装相对比较简单，请自行 baidu/google 相关安装</description>
    </item>
    <item>
      <title>Test-Agent</title>
      <link>/docs/test-agent/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/test-agent/</guid>
      <description>Test-Agent Test-Agent</description>
    </item>
  </channel>
</rss>
